# 第八章 异步编程

异步编程，顾名思义，就是非同步的编程。从高层次上讲，异步操作是在后台执行的操作——程序不会等待异步操作完成，而是立即继续执行下一行代码。如果您还不熟悉异步编程，这个定义可能会显得不够清晰，因为它并没有真正解释什么是异步编程。为了真正理解异步编程模型及其在 Rust 中的工作原理，我们必须首先深入研究替代方案。也就是说，我们需要先理解同步编程模型，然后才能理解异步编程模型。这对于澄清概念和展示使用异步编程的利弊至关重要：异步解决方案并不总是正确的！本章首先将简要介绍异步编程概念的初衷；然后，我们将深入探讨 Rust 中异步技术在底层的实际工作原理。

## 异步有什么作用？

在深入探讨同步和异步编程模型的细节之前，我们首先需要快速了解一下计算机在运行程序时究竟在做什么。计算机运行速度非常快，非常快。事实上，它们的速度快到它们大部分时间都在等待事件发生。除非您正在解压文件、编码音频或进行数字运算，否则您的 CPU 很可能大部分时间都处于空闲状态，等待操作完成。它正在等待网络数据包到达、鼠标移动、磁盘完成写入，或者甚至只是等待主内存的读取完成。从 CPU 的角度来看，大多数此类事件之间都会间隔很长时间。当一个事件发生时，CPU 会运行更多指令，然后再次等待。看看您的 CPU 利用率——它可能处于较低的个位数水平，而且很可能大部分时间都徘徊在这个水平上。

### 同步接口

同步接口允许您的程序（或者更确切地说，程序中的单个线程）一次只执行一个操作；每个操作必须等待前一个同步操作完成后才能运行。您在实际中看到的大多数接口都是同步的：您调用它们，它们执行一些操作，最终在操作完成后返回，然后您的程序就可以从那里继续执行。正如我们将在本章后面看到的那样，这样做的原因是，使操作异步需要相当多的额外机制。除非您需要异步的好处，否则坚持使用同步模型可以减少繁琐的流程。

&nbsp;&nbsp;&nbsp;&nbsp;同步接口隐藏了所有这些等待；应用程序调用一个函数，该函数执行“将这些字节写入此文件”，一段时间后，该函数完成并执行下一行代码。在后台，实际发生的是，操作系统将写入磁盘的操作排队，然后让应用程序进入休眠状态，直到磁盘报告写入完成。应用程序会认为该函数执行时间很长，但实际上它根本没有执行，只是在等待。以这种方式顺序执行操作的接口也通常被称为阻塞接口，因为接口中的操作必须等待某个外部事件发生才能继续执行，因此会阻塞后续执行，直到该事件发生。无论您将接口称为同步接口还是阻塞接口，其基本思想都是相同的：应用程序在当前操作完成之前不会继续执行。当操作等待时，应用程序也在等待。

&nbsp;&nbsp;&nbsp;&nbsp;同步接口通常被认为易于使用，并且易于理解，因为您的代码一次只执行一行。异步编程但它们也允许应用程序一次只执行一件事。这意味着，如果您希望程序等待用户输入或网络数据包，除非您的操作系统专门为此提供操作，否则您将无法完成任务。同样，即使您的应用程序可以在磁盘写入文件时执行其他有用的工作，它也没有这个选项，因为文件写入操作会阻塞执行！

### 多线程

目前，实现并发执行的最常见解决方案是使用多线程。在多线程程序中，每个线程负责执行特定且独立的阻塞操作序列，操作系统会在线程之间进行多路复用，这样，只要有任何线程可以执行，就会有进展。如果一个线程阻塞，其他线程可能仍然可以运行，因此应用程序可以继续执行有用的工作。
&nbsp;&nbsp;&nbsp;&nbsp;通常，这些线程使用同步原语（例如锁或通道）相互通信，以便应用程序仍然可以协调它们的工作。例如，您可能有一个线程等待用户输入，一个线程等待网络数据包，另一个线程等待其中一个线程通过三个线程共享的通道发送消息。
  
&nbsp;&nbsp;&nbsp;&nbsp;多线程赋予了并发性——能够同时执行多个独立操作。运行应用程序的系统（在本例中为操作系统）负责选择未被阻塞的线程，并决定接下来执行哪个线程。如果一个线程被阻塞，它可以选择运行另一个可以继续执行的线程。
  
&nbsp;&nbsp;&nbsp;&nbsp;多线程与阻塞式接口相结合可以让你走得更远，许多可用于生产的软件都是以这种方式构建的。但这种方法并非没有缺点。首先，跟踪所有这些线程很快就会变得繁琐；如果你必须为每个并发任务（包括等待键盘输入等简单任务）启动一个线程，那么线程数量会迅速增加，跟踪所有这些线程如何交互、通信和协调所需的额外复杂性也会随之增加。
  
&nbsp;&nbsp;&nbsp;&nbsp;其次，线程越多，切换成本就越高。每当一个线程停止运行，另一个线程重新启动时，你都需要往返操作系统调度程序，而这并非没有代价。在某些平台上，创建新线程也是一个相当繁重的过程。具有高性能需求的应用程序通常通过重用线程和使用允许您在许多相关操作上进行阻塞的操作系统调用来降低这种成本，但最终您会面临同样的问题：阻塞接口要求您拥有与要进行的阻塞调用数量相同的线程数。
  
&nbsp;&nbsp;&nbsp;&nbsp;最后，线程为程序引入了并行性。并发和并行之间的区别很微妙，但很重要：并发意味着任务的执行是交错的，而并行意味着多个任务同时执行。如果你有两个任务，它们的执行用 ASCII 码表示可能看起来像 _-_-_（并发）与 =====（并行）。多线程并不一定意味着并行——即使你有很多线程，但你可能只有一个核心，因此在给定时间内只有一个线程在执行——但两者通常相辅相成。你可以使用互斥锁或其他同步原语使两个线程在执行时互斥，但这会增加额外的复杂性——线程需要并行运行。虽然并行通常是一件好事——谁不希望自己的程序在更多核心上运行得更快呢——但它也意味着你的程序必须处理对共享数据结构的真正同步访问。这意味着从 `Rc、Cell` 和 `RefCell` 迁移到功能更强大但速度也更慢的 `Arc` 和 `Mutex`。虽然你可能希望在并发程序中使用后者来实现并行，但线程技术迫使你不得不使用它们。我们将在第 10 章更详细地讨论多线程技术。

### 异步接口

既然我们已经探索了同步接口，现在可以看看另一种选择：异步或非阻塞接口。异步接口可能不会立即产生结果，而是指示结果将在稍后某个时间可用。这使得调用者有机会在此期间执行其他操作，而不必进入休眠状态直到该特定操作完成。用 Rust 的说法，异步接口是一种返回 Poll 的方法，如示例 8-1 中定义。

```rust
enum Poll<T> {
 Ready(T),
 Pending
}

// 清单 8-1：异步的核心：“现在就在这里，或者稍后再回来”类型
```
  `Poll` 通常出现在名称以 `poll` 开头的函数的返回类型中——这些方法表示它们可以尝试执行操作而不会阻塞。我们将在本章后面详细讨论它们是如何做到这一点的，但通常情况下，它们会在正常阻塞之前尽可能多地执行操作，然后返回。至关重要的是，它们会记住中断的位置，以便稍后在可以再次进行其他操作时恢复执行。
  
&nbsp;&nbsp;&nbsp;&nbsp;这些非阻塞函数使我们能够轻松地并发执行多个任务。例如，如果您想从网络或用户键盘读取数据（无论哪个先有事件可用），您只需循环轮询两者，直到其中一个返回 `Poll::Ready`。无需任何额外的线程或同步！
  
&nbsp;&nbsp;&nbsp;&nbsp;这里的“循环”这个词可能会让你有点紧张。你肯定不希望你的程序每秒执行三十亿次循环，因为下一次输入可能要等上几分钟。在阻塞接口的世界里，这不算什么问题，因为操作系统只是让线程进入睡眠状态，然后在相关事件发生时将其唤醒。但是，在这个全新的非阻塞世界中，我们如何避免在等待时浪费循环呢？本章剩余内容将主要讨论这个问题。

### 标准化轮询

为了实现每个库都能以非阻塞方式使用，我们可以让每个库的作者编写自己的轮询方法，每个方法的名称、签名和返回类型略有不同——但这很快就会变得笨重。相反，在 Rust 中，轮询是通过 `Future` 特性标准化的。示例 8-2 展示了 `Future` 的一个简化版本（我们将在本章后面讨论真正的 `Future`）。

```rust
trait Future {
 type Output;
 fn poll(&mut self) -> Poll<Self::Output>;
}

// 清单 8-2：Future 特征的简化视图
```

&nbsp;&nbsp;&nbsp;&nbsp;实现 `Future` 特性的类型称为 `Future`，它们表示可能尚未可用的值。`Future` 可以表示下一次网络数据包传入的时间、下一次鼠标光标移动的时间，或者仅仅是某个时间点的流逝。您可以将
`Future<Output = Foo>` 理解为“将来会生成 Foo 的类型”。这类类型在其他语言中通常被称为 Promise——它们承诺最终会生成指定的类型。当 `Future` 最终返回 `Poll::Ready(T)` 时，我们称该 `Future` 解析为 `T`。

&nbsp;&nbsp;&nbsp;&nbsp;有了这个特性，我们可以推广提供轮询方法的模式。我们不必再使用像 `poll_recv` 和 `poll_keypress` 这样的方法，而是可以像 `recv` 和` keypress` 这样的方法，它们都返回 `impl Future` 并带有合适的 `Output` 类型。这不会改变你必须轮询它们的事实——我们稍后会讨论这个问题——但这确实意味着至少有一个标准化的接口来处理这些待处理值，我们不需要到处都使用 `poll_` 前缀。

> 一般来说，在 `Future` 返回 `Poll::Ready` 后，你不应该再次轮询它。如果你这样做，`Future` 完全有理由panic。在返回 Ready 后可以安全轮询的 Future 有时被称为融合 Future。

### 人体工程学的 Future

&nbsp;&nbsp;&nbsp;&nbsp;按照我之前描述的方式编写一个实现 `Future` 的类型相当麻烦。要了解原因，首先看一下示例 8-3 中相当简单的异步代码块，它只是尝试将消息从输入通道 rx 转发到输出通道 tx。

```rust
async fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
    while let Some(t) = rx.next().await {
        tx.send(t).await;
    }
}

// 示例 8-3：使用 async 和 await 实现通道转发 Future
```

&nbsp;&nbsp;&nbsp;&nbsp;这段代码使用了 `async` 和 `await` 语法编写，看起来与对应的同步代码非常相似，并且易于阅读。我们只需循环发送收到的每条消息，直到没有消息为止，每个 `await` 点都对应一个同步变量可能阻塞的位置。现在，想象一下，如果您必须通过手动实现 `Future trait` 来表达这段代码会怎样。由于每次调用 `poll` 都从函数顶部开始，因此您需要打包必要的状态，以便从代码最后返回的位置继续执行。结果会相当糟糕，如示例 8-4 所示。
```rust
enum Forward<T> {
    // 1
    WaitingForReceive(ReceiveFuture<T>, Option<Sender<T>>),
    WaitingForSend(SendFuture<T>, Option<Receiver<T>>),
}
impl<T> Future for Forward<T> {
    type Output = (); // 2
    fn poll(&mut self) -> Poll<Self::Output> {
        match self {
            // 3
            Forward::WaitingForReceive(recv, tx) => {
                if let Poll::Ready((rx, v)) = recv.poll() {
                    if let Some(v) = v {
                        let tx = tx.take().unwrap(); // 4
                        *self = Forward::WaitingForSend(tx.send(v), Some(rx)); // 5
                        // Try to make progress on sending.
                        return self.poll(); // 6
                    } else {
                        // No more items.
                        Poll::Ready(())
                    }
                } else {
                    Poll::Pending
                }
            }
            Forward::WaitingForSend(send, rx) => {
                if let Poll::Ready(tx) = send.poll() {
                    let rx = rx.take().unwrap();
                    *self = Forward::WaitingForReceive(rx.receive(), Some(tx));
                    // Try to make progress on receiving.
                    return self.poll();
                } else {
                    Poll::Pending
                }
            }
        }
    }
}


// 清单 8-4：手动实现通道转发 Future
```

&nbsp;&nbsp;&nbsp;&nbsp;现在你很少需要在 Rust 中编写这样的代码，但它能让我们深入了解底层工作原理，所以让我们来详细了解一下。首先，我们将 `Future` 类型定义为枚举 *1*，用于跟踪当前正在等待的操作。这是因为异步编程当我们返回`Poll::Pending` 时，下一次对 `poll` 的调用将再次从函数顶部开始。我们需要某种方式来了解当前处于什么状态，以便知道应该继续执行哪个操作。此外，我们需要根据正在执行的操作跟踪不同的信息：如果正在等待接收操作完成，我们需要保留该 `ReceiveFuture`（本例中未显示其定义），以便下次轮询时可以轮询它；`SendFuture` 也是如此。这里的选项可能也让你觉得有点奇怪；我们稍后会再讨论它们。
  
&nbsp;&nbsp;&nbsp;&nbsp;当我们为 `Forward` 实现 `Future` 时，我们将其输出类型声明为`()` *2*，因为这个 `Future` 实际上不返回任何内容。相反，当它完成从输入通道到输出通道的所有内容转发后，`Future` 会解析（没有结果）。在一个更完整的示例中，我们的转发类型的输出可能是一个 `Result`，这样它就可以将 `receive()` 和 `send()` 的错误传递回堆栈，并传递给轮询转发完成情况的函数。但这段代码已经够复杂了，所以我们以后再讨论这个问题。
  
&nbsp;&nbsp;&nbsp;&nbsp;当 `Forward` 被轮询时，它需要从上次中断的地方继续执行，我们通过匹配 `self` *3* 中当前持有的枚举变量来找到它。无论我们进入哪个分支，第一步都是轮询当前操作阻塞的 `Future`；如果我们尝试接收，我们轮询 `ReceiveFuture`；如果我们尝试发送，我们轮询 `SendFuture`。如果轮询调用返回 `Poll::Pending`，那么我们就无法继续执行，我们自己返回 `Poll::Pending`。但是，如果当前的 `Future` 解析成功，我们就有事情要做了！

&nbsp;&nbsp;&nbsp;&nbsp;当其中一个内部 `Future` 解析成功时，我们需要通过切换存储在 `self` 中的枚举变量来更新当前操作。为此，我们必须移出 `self` 来调用 `Receiver::receive` 或 `Sender::send`——但我们无法做到这一点，因为我们只有 `&mut self`。因此，我们将需要移动的状态存储在一个 `Option` 中，然后使用`Option::take` *4* 将其移出。这很愚蠢，因为我们无论如何都会覆盖 `self` *5*，因此 `Options` 始终是 `Some`，但有时需要一些技巧，才能让借用检查器满意。
  
&nbsp;&nbsp;&nbsp;&nbsp;最后，如果我们确实取得了进展，我们会再次轮询自身 *6*，以便如果待处理的发送或接收能够立即取得进展，我们就会立即执行。这实际上对于实现真正的 `Future` 特性的正确性是必要的，我们稍后会讨论这一点，但现在先将其视为一种优化。

&nbsp;&nbsp;&nbsp;&nbsp;我们只是手写了一个状态机：一种具有多种可能状态的类型，并根据特定事件在它们之间切换。这还只是个相当简单的状态机。想象一下，对于更复杂的用例，需要编写这样的代码，其中需要额外的中间步骤！

&nbsp;&nbsp;&nbsp;&nbsp;除了编写笨重的状态机之外，我们还必须知道 `Sender::send` 和 `Receiver::receive` 返回的 `Future` 的类型，以便将它们存储在我们的类型中。如果这些方法返回 `impl Future`，我们就无法写出变体的类型。`send` 和 `receive` 方法还必须拥有发送方和接收方的所有权；如果不这样做，它们返回的 Future 的生命周期将与 self 的借用绑定，而这种借用会在我们从 `poll` 返回时结束。但这行不通，因为我们试图将这些 `Future` 存储在 `self` 中。

> 您可能已经注意到，`Receiver` 看起来很像异步版本的 `Iterator`。其他人也注意到了这一点，标准库正在努力为能够有效实现 `poll_next` 的类型添加一个特性。最终，这些异步迭代器（通常称为流）可能会获得一流的语言支持，例如能够直接循环遍历它们！

&nbsp;&nbsp;&nbsp;&nbsp;归根结底，这段代码很难编写、很难阅读、也很难修改。例如，如果我们想添加错误处理，代码复杂度就会显著增加。幸运的是，还有更好的方法！

### async/await

Rust 1.39 引入了 `async` 关键字以及与之密切相关的 `await` 后缀运算符，我们在示例 8-3 的原始示例中就使用了它们。它们共同提供了一种更便捷的机制来编写异步状态机，例如示例 8-5 中那样。具体来说，它们让你能够以某种方式编写代码，使其看起来甚至不像状态机！

```rust
async fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
 while let Some(t) = rx.next().await {
 tx.send(t).await;
 }
}

// 示例 8-5：使用 async 和 await 实现通道转发的 Future，重复示例 8-3
```

&nbsp;&nbsp;&nbsp;&nbsp;如果您对 `async` 和 `await` 不太熟悉，那么清单 8-4 和清单 8-5 之间的区别或许能让您理解 Rust 社区为何如此期待它们的到来。但由于这是一本中级书籍，让我们更深入地了解一下这段简短的代码是如何取代冗长的手动实现的。为此，我们首先需要讨论一下生成器——`async` 和 `await` 的实现机制。

#### 生成器

简而言之，生成器是一段代码，其中包含一些编译器生成的额外位，使其能够在执行过程中停止（或产生），然后从上次产生的位置继续执行。以示例 8-3 中的 `forward` 函数为例。假设它执行到 `send` 调用，但通道当前已满。该函数无法继续执行，但它也不能阻塞（毕竟这是非阻塞代码），因此它需要返回。现在假设通道最终清空，我们想要继续执行 `send` 操作。如果我们再次从顶部调用 `forward`，它会再次调用 `next`，我们之前尝试发送的数据将会丢失，所以这很不妥。相反，我们将 `forward` 函数转换为生成器。

&nbsp;&nbsp;&nbsp;&nbsp;每当`forward`生成器无法继续执行时，它需要将当前状态存储在某个地方，以便当其最终恢复执行时，能够在正确的位置以正确的状态恢复执行。它会通过编译器生成的关联数据结构来保存状态，该数据结构包含生成器在给定时间点的所有状态。然后，该数据结构（也是生成的）上的一个方法允许生成器从其当前状态（存储在 `&mut self` 中）恢复执行，并在生成器再次无法继续执行时再次更新状态。

&nbsp;&nbsp;&nbsp;&nbsp;这种“返回但允许我稍后恢复”的操作称为 `yielding`，实际上意味着它在返回的同时保留了一些额外的状态。当我们稍后想要恢复对 `forward` 的调用时，我们会调用生成器的已知入口点`resume` 方法，对于异步生成器来说就是 `poll` 方法，然后生成器会检查先前存储在 `self` 中的状态，以决定下一步做什么。这与我们在示例 8-4 中手动执行的操作完全相同！换句话说，示例 8-5 中的代码松散地去糖化成了示例 8-6 中所示的假设代码。
  

```rust
generator fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
 loop {
 let mut f = rx.next();
 let r = if let Poll::Ready(r) = f.poll() { r } else { yield };
 if let Some(t) = r {
 let mut f = tx.send(t);
 let _ = if let Poll::Ready(r) = f.poll() { r } else { yield };
 } else { break Poll::Ready(()); }
 }
}

// 示例 8-6：将 async/await 脱糖为生成器
```

&nbsp;&nbsp;&nbsp;&nbsp;在撰写本文时，生成器实际上在 Rust 中不可用——它们仅由编译器在内部使用，用于实现 `async/await`——但这种情况将来可能会改变。生成器在很多情况下都很有用，例如，实现迭代器时无需携带结构体，或者实现一个 `impl Iterator` 来计算如何一次只产生一个元素。

&nbsp;&nbsp;&nbsp;&nbsp;如果你仔细观察清单 `8-5` 和 `8-6`，你可能会觉得它们有点不可思议，一旦你知道每个 `await` 或 `yield` 实际上都是函数的返回。毕竟，函数中有几个局部变量，而且我们不清楚，它们在稍后恢复时是如何恢复的。这就是生成器的编译器生成部分发挥作用的地方。编译器透明地注入代码，在执行时将这些变量持久化到生成器关联的数据结构中，并从中读取它们，而不是从堆栈中读取。因此，如果你声明、写入或读取某个局部变量 `a`，你实际上是在操作类似于 `self.a` 的东西。问题解决了！这一切真的非常奇妙。

&nbsp;&nbsp;&nbsp;&nbsp;手动 `Forward` 实现和 `async/await` 版本之间一个微妙但重要的区别是，后者可以跨 `yield point` 持有引用。这使得示例 `8-5` 中的 `Receiver::next` 和 `Sender::send` 等函数能够接受 `&mut self` ，而不是示例 `8-4` 中接受的 `self` 。如果我们尝试在手动状态机实现中为这些方法使用 `&mut self` 接收器，借用检查器将无法强制执行 `Forward` 中存储的 `Receiver` 在 `Receiver::next` 调用和它返回的 `Future` 解析之间不能被引用，因此它会拒绝该代码。只有将 `Receiver` 移到 `Future` 中，我们才能让编译器相信 `Receiver` 无法通过其他方式访问。同时，使用 `async/await`，借用检查器可以在编译器将代码转换为状态机之前检查代码，并验证 `rx` 确实在 `Future` 被丢弃之后（即对其进行的 `await` 返回之前）不会被再次访问。

> 生成器的大小
> 
>&nbsp;&nbsp;&nbsp;&nbsp;用于支持生成器状态的数据结构必须能够在任何一个 `yield` 点保存组合状态。例如，如果你的 `async fn` 包含一个 `[u8; 8192]`，那么这 8KiB 必须存储在生成器本身中。即使你的 `async fn` 只包含较小的局部变量，它也必须包含它正在等待的任何 `Future`，因为它需要能够在稍后调用 poll 时轮询这样的 Future。
>&nbsp;&nbsp;&nbsp;&nbsp;这种嵌套意味着生成器，以及基于异步函数和块的 `Future`，可能会变得非常大，而代码中却没有任何明显的迹象表明这种增加的大小。这反过来会影响程序的运行时性能，因为这些巨大的生成器可能需要在函数调用之间以及数据结构中进行复制，这相当于大量的内存复制。事实上，你通常可以通过在应用程序的性能配置文件中查找 `memcpy` 函数中花费的过多时间来识别基于生成器的 Future 的大小何时影响了性能！
> &nbsp;&nbsp;&nbsp;&nbsp;然而，找到这些大型的 Future 并不总是那么容易，通常需要手动识别冗长或复杂的异步函数链。`Clippy` 将来或许可以解决这个问题，但在撰写本文时，你只能依靠自己。当你找到一个特别大的 `Future` 时，你有两个选择：你可以尝试减少异步函数所需的本地状态量，或者你可以将 `Future` 移动到堆中（使用 `Box::pin`），这样移动 `Future` 只需要移动指向它的指针即可。后者是迄今为止最简单的方法，但它也引入了额外的内存分配和指针间接寻址。最好的办法通常是将有问题的 `Future` 放在堆上，测量性能，然后使用性能基准测试来指导你下一步的操作。

#### Pin 和 Unpin

我们还没完。虽然生成器很简洁，但正如我之前描述的，这项技术带来了一个挑战。特别是，如果生成器（或者说异步块）中的代码引用了局部变量，会发生什么情况，这一点尚不清楚。在示例 8-5 的代码中，如果下一条消息不可用，`rx.next()` 返回的 `Future` 必须持有对 `rx` 的引用，这样它才能知道在生成器下次恢复时从哪里重试。当生成器 `yield` 时，`Future` 及其包含的引用会被存储在生成器内部。但是，如果移动了生成器，会发生什么情况呢？具体来说，请看示例 8-7 中调用 `forward` 的代码。

```rust
async fn try_forward<T>(rx: Receiver<T>, tx: Sender<T>) -> Option<impl Future>
{
 let mut f = forward(rx, tx);
 if f.poll().is_pending() { Some(f) } else { None }
}

// 示例 8-7：轮询后移动 Future
```

&nbsp;&nbsp;&nbsp;&nbsp;`try_forward` 函数仅轮询一次转发，以便在不阻塞的情况下转发尽可能多的消息。如果接收方仍可能生成更多消息（即，如果它返回的是 `Poll::Pending` 而不是 `Poll::Ready(None)`），则这些消息将被推迟到稍后的某个时间转发，方法是将转发 `Future` 返回给调用者，调用者可以选择在合适的时间再次轮询。

&nbsp;&nbsp;&nbsp;&nbsp;让我们利用目前对 `async` 和 `await` 的了解来解释一下这里发生了什么。当我们轮询 `forward` 生成器时，它会执行 `while` 循环，次数未知，最终返回以下两种情况：
如果接收方已结束，则返回 `Poll::Ready(())`；否则，返回 `Poll::Pending`。如果返回 `Poll::Pending`，则生成器包含一个从 `rx.next()` 或 `tx.send(t)` 返回的 `Future`。这两个 `Future` 都包含对最初传递给 `forward` 的参数之一（分别为 `rx` 和 `tx`）的引用，这些参数也必须存储在生成器中。但是，当 `try_forward` 返回整个生成器时，生成器的字段也会移动。因此，`rx` 和 `tx` 不再驻留在内存中的相同位置，并且存储在暂存 `Future` 中的引用不再指向正确的数据！
&nbsp;&nbsp;&nbsp;&nbsp;我们在这里遇到的是一个自引用数据结构的例子：它同时保存数据和对数据的引用。使用生成器，这些自引用结构非常容易构建，如果无法支持它们，将会对人机工程学造成重大打击，因为这意味着你无法在任何 `yield point` 上保存引用。Rust 中支持自引用数据结构的（巧妙的）解决方案是 `Pin` 类型和 `Unpin trait`。简而言之，`Pin` 是一个包装器类型，可以防止被包装的类型被（安全地）移动；而 `Unpin` 是一个标记 `trait`，表示可以安全地从 `Pin` 中移除实现类型。

##### Pin

这里有很多细微差别需要讲解，所以我们先从 `Pin` 包装器的具体使用开始。示例 8-2 提供了 Future 特性的简化版本，但现在我们可以开始分解简化版本的一部分。示例 8-8 展示了更接近最终版本的 `Future` 特性。

```rust
trait Future {
 type Output;
 fn poll(self: Pin<&mut Self>) -> Poll<Self::Output>;
}

// 示例 8-8：使用 Pin 的 Future trait 的不太简化的视图
```
具体来说，此定义要求你对 `Pin<&mut Self>` 调用 poll 函数。一旦你在 `Pin` 后面有一个值，就构成了一个约定，该值永远不会再移动。这意味着你可以随心所欲地在内部构建自引用，就像你对生成器所做的那样。

> 虽然 `Future` 使用了 `Pin`，但 `Pin` 并不与 `Future` 特性绑定——你可以将 `Pin` 用于任何自引用数据结构。

但是，如何让 `Pin` 调用 `poll` 呢？`Pin` 又如何确保它所包含的值不会移动呢？为了理解这个魔法是如何运作的，我们来看看 `std::pin::Pin` 的定义及其一些关键方法，如清单 8-9 所示。

```rust
struct Pin<P> { pointer: P }
impl<P> Pin<P> where P: Deref {
 pub unsafe fn new_unchecked(pointer: P) -> Self;
}
impl<'a, T> Pin<&'a mut T> {
 pub unsafe fn get_unchecked_mut(self) -> &'a mut T;
}
impl<P> Deref for Pin<P> where P: Deref {
 type Target = P::Target;
 fn deref(&self) -> &Self::Target;
}

// 示例 8-9：std::pin::Pin 及其关键方法
```

&nbsp;&nbsp;&nbsp;&nbsp;这里有很多内容需要解释，我们需要反复查看示例 8-9 中的定义，才能理解所有内容，所以请耐心等待。
&nbsp;&nbsp;&nbsp;&nbsp;首先，你会注意到 `Pin` 持有一个指针类型。也就是说，它不是直接持有某个 `T`，而是持有一个类型 `P`，该类型 `P` 通过 `Deref` 解引用到 `T`。这意味着，你拥有的不是 `Pin<MyType>`，而是 `Pin<Box<MyType>>` 或 `Pin<Rc<MyType>>` 或 `Pin<&mut MyType>`。这种设计的原因很简单—— `Pin` 的主要目标是确保一旦将 `T` 放在 `Pin` 后面，该 `T` 就不会移动，因为移动可能会使存储在 `T` 中的自引用失效。如果 `Pin` 只是直接持有一个 `T`，那么只需移动 `Pin` 就足以使该不变量失效！在本节的剩余部分，我将 `P` 称为指针类型，将 `T` 称为目标类型。
&nbsp;&nbsp;&nbsp;&nbsp;接下来，请注意 `Pin` 的构造函数 `new_unchecked` 是不安全的。这是因为编译器无法真正检查指针类型是否确实承诺了指向的（目标）类型不会再次移动。例如，假设栈上的变量 `foo`。如果 `Pin` 的构造函数是安全的，我们可以执行 `Pin::new(&mut foo)`，调用一个需要 `Pin<&mut Self>` 的方法（因此假设 `Self` 不会再次移动），然后丢弃 `Pin`。此时，我们可以随意修改 `foo`，因为它不再是借用的——包括移动它！然后我们可以再次固定它并调用相同的方法，但这并不会更清楚地知道，它第一次构造的任何自引用指针现在都无效了。

> Pin构造函数安全
>
> `Pin` 的构造函数不安全的另一个原因是，它的安全性取决于自身安全的 `trait` 的实现。例如，`Pin<P>` 实现 `get_unchecked_mut` 的方式是使用 `P` 的 `DerefMut::deref_mut` 实现。虽然对 `get_unchecked_mut` 的调用是不安全的，但 `P` 的 `DerefMut` 实现却并非如此。然而，它接收一个 `&mut self`，因此可以自由地（并且无需不安全代码）移动 `T`。Drop 也是如此。因此，`Pin::new_unchecked` 的安全性要求不仅在于指针类型不允许再次移动目标类型（例如 `Pin<&mut T>` 示例中的情况），还在于其 `Deref`、`DerefMut` 和 `Drop` 实现不会将指向的值移动到它们接收的 `&mut self` 之后。

&nbsp;&nbsp;&nbsp;&nbsp;接下来我们进入 `get_unchecked_mut` 方法，它返回一个指向 `Pin` 指针类型背后 `T` 的可变引用。此方法同样不安全，因为一旦我们给出一个 `&mut T`，调用者必须保证不会使用该 `&mut T` 移动 `T` 或以其他方式使其内存失效，以免任何自引用失效。如果此方法不安全，调用者可以调用一个接受 `Pin<&mut Self>` 参数的方法，然后在两个 `Pin<&mut _>` 上调用 `get_unchecked_mut` 的安全版本，然后使用 `mem::swap` 交换 `Pin` 背后的值。如果我们随后在任一 `Pin` 上再次调用一个接受 `Pin<&mut Self>` 参数的方法，它假设 Self 未移动的假设就会被违反，并且它存储的任何内部引用都将失效！

&nbsp;&nbsp;&nbsp;&nbsp;或许令人惊讶的是，`Pin<P>` 总是实现 `Deref<Target = T>`，而这完全是安全的。原因在于，`&T` 不允许你在不编写其他不安全代码（例如，我们将在第九章讨论的 `UnsafeCell`）的情况下移动 `T`。这很好地说明了为什么不安全块的作用域会超出其包含的代码。如果你在应用程序的某个部分编写了一些代码，使用 `UnsafeCell`（不安全地）替换了 `&` 后面的 `T`，那么这个 `&T` 可能最初来自 `Pin<&mut T>`，而你现在违反了 `Pin` 后面的 `T` 永远不能移动的不变性，即使你不安全地替换 `&T` 的地方甚至没有提到 `Pin！`。

> 如果您在阅读本章时浏览过 `Pin` 文档，您可能已经注意到 `Pin::set`，它接受一个 `&mut self` 和一个 `<P as Deref>::Target`，并安全地更改 `Pin` 后面的值。这是可能的，因为 `set` 不会返回之前固定的值——它只是将其放置到原处，并将新值存储在那里。因此，它不违反固定不变式：将旧值放置到 `Pin` 之后，旧值就永远不会在 `Pin` 之外被访问。

##### Unpin:  安全 Pinning 的关键

此时你可能会问：既然获取可变引用本身就不安全，为什么不让 `Pin` 直接持有一个 `T` 呢？也就是说，与其要求通过指针类型进行间接访问，不如为 `get_unchecked_mut` 制定一个约定，规定只有在 `Pin` 未移动的情况下调用它才是安全的。这个问题的答案在于指针设计所实现的 `Pin` 的简洁安全使用。回想一下，我们最初想要 `Pin` 的原因是，这样我们就可以拥有可能包含对自身引用的目标类型（例如生成器），并保证它们的方法目标类型没有移动，从而内部的自引用仍然有效。`Pin` 让我们可以使用类型系统来强制执行这种保证，这很棒。但不幸的是，就目前的设计而言，`Pin` 的使用非常笨重。这是因为它总是需要不安全的代码，即使你使用的目标类型不包含任何自引用，因此它不关心它是否已被移动。

&nbsp;&nbsp;&nbsp;&nbsp;这时，标记特质 `Unpin` 就派上用场了。一个类型的 `Unpin` 实现只是断言，当用作目标类型时，该类型可以安全地从 `Pin` 中移出。也就是说，该类型承诺永远不会使用 `Pin` 的任何关于引用对象在用作目标类型时不会再次移动的保证，因此这些保证可能会被破坏。`Unpin` 是一个自动特质，就像 `Send` 和 `Sync` 一样，因此编译器会为任何仅包含 `Unpin` 成员的类型自动实现。只有明确选择退出 `Unpin` 的类型（例如生成器）以及包含这些类型的类型才会被 `!Unpin` 实现。

&nbsp;&nbsp;&nbsp;&nbsp;对于 `Unpin` 的目标类型，我们可以为 `Pin` 提供一个更简单、更安全的接口，如清单 8-10 所示。

```rust
impl<P> Pin<P> where P: Deref, P::Target: Unpin {
 pub fn new(pointer: P) -> Self;
}
impl<P> DerefMut for Pin<P> where P: DerefMut, P::Target: Unpin {
 fn deref_mut(&mut self) -> &mut Self::Target;
}

// 示例 8-10：用于 Unpin 目标类型的安全 Pin API
```

为了理解示例 8-10 中的安全 API，请思考示例 8-9 中不安全方法的安全要求：函数 `Pin::new_unchecked` 是不安全的，因为调用者必须保证引用对象不能移出 `Pin`，并且指针类型的 `Deref`、`DerefMut` 和 `Drop` 的实现不会通过它们接收到的引用移动引用对象。这些要求是为了确保一旦我们将 `Pin` 赋予 T，就永远不会再次移动该 `T`。但是，如果 `T` 是 Unpin 的，它声明即使它之前被固定，它也不关心它是否被移动，因此即使调用者不满足任何这些要求-也没关系！

&nbsp;&nbsp;&nbsp;&nbsp;类似地，`get_unchecked_mut` 是不安全的，因为调用者必须保证它不会将 `T` 从 `&mut T` 中移出——但有了 `T: Unpin`，`T` 已经声明
即使在被固定后也可以被移动，因此安全要求不再重要。这意味着对于 `Pin<P>` 中 `P::Target:Unpin` 的情况，我们可以简单地提供这两个方法的安全变体（`DerefMut` 是 `get_unchecked_mut` 的安全版本）。事实上，我们甚至可以提供一个`Pin::into_inner` 函数，如果目标类型是 `Unpin`，它只会返回拥有的 `P`，因为 Pin 本身就无关紧要！

##### 获得Pin的方式

有了对 `Pin` 和 `Unpin` 的新理解，我们现在可以开始使用示例 8-8 中需要 `Pin<&mut Self>` 的新 `Future` 定义了。第一步是构造所需的类型。如果 `Future` 类型是 `Unpin`，那么这一步很简单——我们只需使用 `Pin::new(&mut future)`。如果不是 `Unpin`，我们可以通过两种主要方式之一来固定 `Future`：固定到堆或固定到栈。
&nbsp;&nbsp;&nbsp;&nbsp;让我们从固定到堆开始。`Pin` 的主要约定是，一旦某个对象被固定，它就不能移动。固定 API 负责遵守 `Pin` 上所有方法和特征的约定，因此，任何构造 `Pin` 的函数的主要作用是确保如果 `Pin` 本身移动，
其引用值也不会移动。最简单的方法是将引用对象放置在堆上，然后在 `Pin` 中放置一个指向该引用对象的指针。然后，您可以随心所欲地移动 `Pin`，但目标对象将保持在原处。这就是（安全）方法 `Box::pin` 背后的原理，该方法接受一个 `T` 并返回一个 `Pin<Box<T>>`。它没有什么神奇之处；它只是断言 `Box` 遵循 `Pin` 的构造函数、`Deref` 和 `Drop` 约定。

> Unpin Box
>
> 既然我们讨论的是 `Box`，不妨看一下 `Box` 的 `Unpin` 实现。`Box` 类型会无条件地为任何 `T` 实现 `Unpin`，即使该 `T` 不是 `Unpin` 的。考虑到之前的断言，`Unpin` 是一个自动特征，通常只有当该类型的所有成员也都是 `Unpin` 时才会实现。`Box` 是个例外，原因与它能够提供安全的 `Pin` 构造函数相同：如果移动 `Box<T>`，则不会移动 `T`。换句话说，无条件实现断言即使 `T` 不能从 `Pin` 中移出，也可以将 `Box<T>` 移出 `Pin`。但请注意，这不允许你将 `!Unpin` 的 `T` 移出 `Pin<Box<T>>`。

&nbsp;&nbsp;&nbsp;&nbsp;另一种选择是固定到堆栈，这稍微复杂一些，并且在撰写本文时需要一些不安全的代码。我们必须确保在删除带有 `&mut` 的 `Pin` 后，固定的值无法被访问。我们通过隐藏值来实现这一点，如示例 8-11 中的宏所示，或者使用提供此宏的 crate 之一。将来有一天，它甚至可能会被添加到标准库中！

```rust
macro_rules! pin_mut {
 ($var:ident) => {
 let mut $var = $var;
 let mut $var = unsafe { Pin::new_unchecked(&mut $var) };
 }
}

// 示例 8-11：用于固定到堆栈的宏
```

&nbsp;&nbsp;&nbsp;&nbsp;通过获取要固定到堆栈的变量的名称，该宏确保调用者已将要固定的值固定在堆栈的某个位置。`$var` 的遮蔽确保调用者无法删除 `Pin` 并继续使用未固定的值（这将违反任何 `!Unpin` 目标类型的 `Pin` 契约）。通过移动存储在 `$var` 中的值，该宏还确保调用者无法在不删除原始变量的情况下删除绑定宏声明的 `$var`。具体来说，如果没有这行代码，调用者可以这样写（注意额外的作用域）：

```rust
let foo = /* */; { pin_mut!(foo); foo.poll() }; foo.mut_self_method();
```

&nbsp;&nbsp;&nbsp;&nbsp;这里，我们传入一个固定的 `foo` 实例进行轮询，但之后我们又对没有 `Pin` 的 foo 使用了 `&mut`，这违反了 `Pin` 契约。另一方面，由于额外的重新赋值，该代码也会将 `foo` 移动到新的范围，导致其在范围结束后无法使用。

&nbsp;&nbsp;&nbsp;&nbsp;因此，与 `Box::pin` 不同，在堆栈上固定需要不安全的代码，但可以避免 `Box` 引入的额外分配，并且在 `no_std` 环境中也能正常工作。

#### 回到Futrue

现在，我们已经有了固定的 `Future`，并且知道这意味着什么。但你可能已经注意到，这些重要的固定内容在你使用 `async` 和 `await` 编写的大多数异步代码中都没有出现。这是因为编译器隐藏了它们。
&nbsp;&nbsp;&nbsp;&nbsp;回想一下我们讨论清单 8-5 的时候，我告诉过你，`<expr>.await` 会脱糖成如下形式：

```rust
loop { if let Poll::Ready(r) = expr.poll() { break r } else { yield } }
```
&nbsp;&nbsp;&nbsp;&nbsp;这其实只是稍微简化了一下，因为正如我们所见，只有当你拥有 `Future` 的 `Pin<&mut Self>` 时，你才能调用 `Future::poll`。实际上，去语法糖化要复杂一些，如示例 8-12 所示。

```rust
match expr { // 1
 mut pinned => loop {
   match unsafe { Pin::new_unchecked(&mut pinned) }.poll() { // 2
 Poll::Ready(r) => break r,
 Poll::Pending => yield,
 }
 }
}

// 示例 8-12：更精确的 <expr>.await 去糖化
```
&nbsp;&nbsp;&nbsp;&nbsp; `match` **1** 是一个简洁的简写，它不仅确保扩展仍然是一个有效的表达式，而且还将表达式结果移动到一个变量中，然后我们可以将其固定在堆栈上。除此之外，主要的新增功能是对 `Pin::new_unchecked` **2** 的调用。该调用是安全的，因为对于要轮询的异步块，根据 *Future::poll* 的签名，它必须已经被固定。并且异步块已经轮询，我们才能到达调用 *Pin::new_unchecked*，因此生成器状态已被固定。由于 `pinned` 存储在与异步块对应的生成器中（必须如此，以便 `yield` 能够正确恢复），我们知道 `pinned` 不会再次移动。此外，一旦我们进入循环，`pinned` 就无法访问，除非通过 `Pin`，所以任何代码都无法移出`pinned` 中的值。因此，我们满足了 `Pin::new_unchecked` 的所有安全要求，代码是安全的。

### 去休眠吧

我们已经深入研究了 `Pin` 的底层原理，但现在我们已经解决了这个问题，关于 `Future` 的另一个问题可能让你感到头疼。如果调用 `Future::poll` 返回 `Poll::Pending`，你需要一个东西在稍后再次调用 `poll` 来检查是否能够取得进展。这个东西通常被称为执行器。你的执行器可以是一个简单的循环，轮询你正在等待的所有 `Future`，直到它们都返回 `Poll::Ready`，但这会消耗大量的 CPU 周期，而这些 CPU 周期你本可以用于其他更有用的事情，比如运行你的 Web 浏览器。相反，我们希望执行器能够完成所有它能做的有用的工作，然后进入休眠状态。它应该保持休眠状态，直到其中一个 `Future` 能够取得进展，然后才被唤醒执行另一次传递，然后再进入休眠状态。

#### 唤醒

决定何时使用给定 `Future` 进行检查的条件多种多样。可能是“当网络数据包到达此端口时”、“当鼠标光标移动时”、“当有人在此通道上发送消息时”、“当 CPU 收到特定中断时”，甚至是“经过这么长时间后”。此外，开发者还可以编写自己的 `Future`，将多个 `Future` 封装在一起，这样就可以拥有多个唤醒条件。有些 `Future` 甚至可能引入完全自定义的唤醒事件。

&nbsp;&nbsp;&nbsp;&nbsp;为了适应这些众多的用例，Rust 引入了 `Waker` 的概念：一种唤醒执行器以发出可以取得进展的信号的方式。`Waker` 是整个 `Future` 机制运转的关键。执行器会构造一个 `Waker`，与执行器用于进入休眠状态的机制集成，并将 `Waker` 传递给它轮询的任何 `Future`。怎么做到的？通过 `Future::poll` 的附加参数，我一直对你隐瞒着这个参数。抱歉，代码清单 8-13 给出了 Future 的最终定义——不再是谎言！

```rust
trait Future {
 type Output;
 fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
}

// 示例 8-13：带有 Context 的实际 Future trait
```

&nbsp;&nbsp;&nbsp;&nbsp;`&mut Context` 包含 `Waker`。该参数是一个 `Context`，而不是直接是一个 `Waker`，因此我们可以根据需要为 `Future` 添加额外的上下文来扩充异步生态系统。
&nbsp;&nbsp;&nbsp;&nbsp;`Waker` 的主要方法是 `wake`（以及引用变体 `wake _by_ref`），当 `Future` 能够再次执行时，应该调用该方法。`wake` 方法不接受任何参数，其效果完全由构造 `Waker` 的执行器定义。`Waker` 秘密地对执行器进行了泛型。或者更准确地说，无论 `Waker` 构造了什么，都可以决定在调用 `Waker::wake`、克隆 `Waker` 以及丢弃 `Waker` 时会发生什么。所有这些都通过手动实现的虚表进行，其功能类似于我们在第二章中讨论过的动态分发。
&nbsp;&nbsp;&nbsp;&nbsp;构造 `Waker` 的过程有些复杂，其机制对于使用 `Waker` 来说并非那么重要，但您可以在标准库中的 `RawWakerVTable` 类型中看到构建块。它有一个构造函数，接受 `wake` 和 `wake_by_ref` 以及 `Clone` 和 `Drop` 的函数指针。`RawWakerVTable` 通常由执行器的所有 `Waker` 共享，它与一个原始指针捆绑在一起，该指针用于保存特定于每个 `Waker` 实例的数据（例如它用于哪个 `Future`），并转换为 `RawWaker`。然后，该指针会被传递给 `Waker::from_raw` 以生成一个安全的 `Waker`，该 `Waker` 可以传递给 `Future::poll`。

#### 履行Poll约定
到目前为止，我们只是略过了 `Future` 和 `Waker` 之间实际的作用。这个想法相当简单：如果 `Future::poll` 返回 `Poll::Pending`，那么 `Future` 有责任确保在下次能够继续执行时，某个 `Future` 会在提供的 `Waker` 上调用 `wake` 方法。大多数 `Future` 都遵循此特性，只有当其他 `Future` 也返回 `Poll::Pending` 时，才会返回 `Poll::Pending`；这样，它就自然而然地履行了 `poll` 的约定，因为内部 `Future` 也必须遵循相同的约定。但不可能一直都是乌龟。在某个时刻，你会遇到一个 `Future`，它不会轮询其他 `Future`，而是执行一些操作，例如写入网络套接字或尝试在通道上接收数据。这些 `Future` 通常被称为 `Leaf Future`，因为它们没有子 `Future`。`Leaf Future` 没有内部 `Future`，而是直接表示一些可能尚未准备好返回结果的资源。

> 正是由于Poll约定，清单 8-4 中的递归轮询调用 6 才对正确性至关重要。

&nbsp;&nbsp;&nbsp;&nbsp;`Leaf Future` 通常有两种形式：一种等待源自同一进程的事件（例如通道接收器），另一种等待源自进程外部的事件（例如 TCP 数据包读取）。等待内部事件的 `Future` 往往遵循相同的模式：将 `Waker` 存储在唤醒代码可以找到的地方，并让该代码在生成相关事件时调用 `Waker` 的 `wake` 方法。例如，考虑一个 `Leaf Future`，它必须在内存通道上等待消息。它将 `Waker` 存储在发送方和接收方共享的通道部分中，然后返回 `Poll::Pending`。当发送方稍后出现并向通道注入消息时，它会注意到等待的接收方留下的 `Waker`，并在从 `send` 返回之前调用 `Waker` 的 `wake` 方法。现在接收方已被唤醒，Poll合约得以执行。

&nbsp;&nbsp;&nbsp;&nbsp;处理外部事件的`Leaf Future`更加复杂，因为生成它们所等待事件的代码对 `Future` 或唤醒程序一无所知。生成代码通常是操作系统内核，它知道磁盘何时就绪或计时器何时到期，但也可能是 C 库，在操作完成时调用 Rust 的回调，或其他类似的外部实体。像这样包装外部资源的`Leaf Future` 可以启动一个线程来执行阻塞系统调用（或等待 C 回调），然后使用内部唤醒机制，但这会造成浪费；每次操作需要等待时，你都需要启动一个线程，这样就会留下许多一次性线程在等待。

&nbsp;&nbsp;&nbsp;&nbsp;相反，执行器倾向于提供`Leaf Future`的实现，这些实现在后台与执行器进行通信，以安排与操作系统的适当交互。具体如何协调取决于执行器和操作系统，但粗略地说，执行器会跟踪下次进入休眠状态时应该监听的所有事件源。当`Leaf Future`意识到它必须等待外部事件时，它会更新该执行器的状态（执行器知道该状态，因为它是由执行器 `crate` 提供的），以将该外部事件源与其 `Waker` 一起包含。当执行器无法再继续执行时，它会收集各个待处理的`Leaf Future`正在等待的所有事件源，并对操作系统进行一次大的阻塞调用，告诉操作系统，当`Leaf Future`正在等待的任何资源有新事件时返回。在 Linux 上，这通常通过 `epoll` 系统调用实现；Windows、BSD、macOS 以及几乎所有其他操作系统都提供了类似的机制。当该调用返回时，执行器会对所有与操作系统报告事件的事件源关联的唤醒器调用唤醒，从而履行Poll合约。

> 反应器是执行器的一部分，`Leaf Future`会向其注册事件源，而执行器在没有其他有用工作可做时会等待反应器。虽然可以将执行器和反应器分开，但将它们捆绑在一起通常可以提高性能，因为两者更容易协同优化。

&nbsp;&nbsp;&nbsp;&nbsp;`Leaf Future`与执行器紧密集成的一个连锁效应是，一个执行器 `crate` 中的`Leaf Future`通常无法与其他执行器一起使用。或者至少，除非`Leaf Future`的执行器也在运行，否则它们无法使用。当`Leaf Future`去存储其唤醒器并注册它正在等待的事件源时，它所依赖的执行器需要设置该状态并处于运行状态，以便事件源能够被实际监控并最终被唤醒。有一些方法可以解决这个问题，例如让`Leaf Future`生成一个执行器（如果尚未运行），但这并不总是可取的，因为这意味着应用程序最终可能会同时运行多个执行器，这会降低性能，并且意味着您必须在调试时检查多个执行器的状态。

&nbsp;&nbsp;&nbsp;&nbsp;希望支持多个执行器的库 `crate` 必须对其Leaf资源实现泛型。例如，库可以存储一个通用的 `T: AsyncRead+AsyncWrite`，而不是使用特定执行器的`TcpStream` 或 `File Future` 类型。然而，生态系统尚未确定这些 `trait` 的具体形式以及需要哪些 `trait`，因此目前很难让代码真正在执行器上实现泛型。例如，虽然 `AsyncRead`和 `AsyncWrite` 在整个生态系统中比较常见（或者可以根据需要轻松调整），但目前还没有用于在后台运行 `Future`（生成 `Future`，我们稍后会讨论）或表示计时器的 `trait`。

#### “唤醒”是一个误称

您可能已经意识到，`Waker::wake` 似乎不一定会唤醒任何东西。例如，对于外部事件（如上一节所述），执行器已经处于唤醒状态，如果它调用属于该执行器的 `Waker` 的 `wake` 方法，那么它似乎很愚蠢！事实上，`Waker::wake` 这个名称有点用词不当——实际上，它表示某个特定的 `Future` 处于可运行状态。也就是说，它告诉执行器，它应该确保在处理这个特定的 `Future` 时对其进行轮询，而不是再次进入休眠状态，因为这个 `Future` 可以继续执行。如果执行器当前正在休眠，这可能会唤醒它，因此它会轮询该 `Future`，但这更像是一种副作用，而不是它的主要目的。

&nbsp;&nbsp;&nbsp;&nbsp;执行器需要知道哪些 `Future` 处于可运行状态，这有两个原因。首先，它需要知道何时可以停止轮询 `Future`，并进入休眠状态；仅仅轮询每个 `Future` 直到它返回 `Poll::Pending` 是不够的，因为轮询较晚的 `Future` 可能会使较早的 `Future` 继续运行。考虑这样一种情况：两个 `Future` 在通道上互相传递消息。当你轮询其中一个 `Future` 时，另一个 `Future` 就会准备就绪，反之亦然。在这种情况下，执行器不应该进入休眠状态，因为总有更多工作要做。

&nbsp;&nbsp;&nbsp;&nbsp;其次，了解哪些 `Future` 处于可运行状态，可以让执行器避免不必要地轮询 `Future`。如果执行器管理着数千个待处理的 `Future`，它不应该仅仅因为某个事件使其中一个 `Future` 变为可运行状态就轮询所有 `Future`。如果这样做，执行异步代码的速度确实会非常慢。

#### 任务和子执行器

异步程序中的 `Future` 构成一棵树：一个 `Future` 可能包含任意数量的其他 `Future`，而这些 `Future` 又可能包含其他 `Future`，一直到与唤醒器交互的`Leaf Future`。每棵树的根是你赋予执行器主“运行”函数的 `Future`。这些根 `Future` 被称为任务，它们是执行器和 `Future` 树之间的唯一接触点。执行器对任务调用 `poll` 函数，从此时起，每个包含的 `Future` 的代码必须确定要轮询哪些内部 `Future` 作为响应，一直到它们相关的叶子。

&nbsp;&nbsp;&nbsp;&nbsp;执行器通常会为每个轮询的任务构建一个单独的 `Waker`，这样，当稍后调用 `wake` 时，它们就能知道哪个任务刚刚被置为可运行状态，并可以将其标记为可运行状态。这就是 `RawWaker` 中原始指针的作用——在共享各种 `Waker` 方法代码的同时，区分不同的任务。

&nbsp;&nbsp;&nbsp;&nbsp;当执行器最终轮询一个任务时，该任务会从其 `Future::poll` 实现的顶层开始运行，并必须从那里决定如何到达更深层次的 `Future`，以便现在可以继续执行。由于每个 `Future` 只知道自己的字段，而对整个 `Future` 树一无所知，因此，这一切都是通过遍历 `Future`树中一条边的 `poll` 调用来实现的。

&nbsp;&nbsp;&nbsp;&nbsp;选择轮询哪个内部 `Future` 通常是显而易见的，但并非总是如此。在 `async/await` 的情况下，要轮询的 `Future` 就是我们被阻塞等待的 `Future`。但是，对于等待多个 `Future` 中的第一个取得进展（通常称为 `select`）或等待一组 `Future` 中所有 `Future` 取得进展（通常称为 `join`）的 `Future`，则有很多选择。必须做出这种选择的 `Future` 本质上是一个子执行器。它可以轮询其所有内部 `Future`，但这样做可能非常浪费。因此，这些子执行器通常会在对任何内部 `Future` 调用 `poll` 之前，先用自己的 `Waker` 类型包装它们在 `poll` 的 `Context` 中接收到的 `Waker`。在包装代码中，它们在对原始 `Waker` 调用 `wake` 之前，将刚刚轮询的 `Future` 标记为处于自身状态的可运行状态。这样，当执行器最终再次轮询子执行器的 `Future` 时，子执行器可以查阅其自身的内部状态，以确定是哪个内部 `Future` 导致了当前的轮询调用，然后仅轮询这些 `Future`。

> 异步代码中的阻塞
>
> 从异步代码调用同步代码时必须谨慎，因为执行器线程执行当前任务所花费的时间，就等于它没有用于运行其他任务的时间。如果某个任务长时间占用当前线程而没有返回执行器（这种情况可能发生在执行阻塞系统调用（例如 `std::sync::sleep`）、运行偶尔不会返回的子执行器，或者在没有等待的紧密循环中运行），那么当前执行器线程负责的其他任务将无法在此期间运行。通常，这表现为某些任务可以取得进展（例如客户端连接时）和实际执行之间的长时间延迟。
> 一些多线程执行器实现了工作窃取技术，空闲的执行器线程会从繁忙的执行器线程中窃取任务，但这更多的是一种缓解措施，而非解决方案。最终，你可能会遇到这样的情况：所有执行器线程都被阻塞，因此在其中一个阻塞操作完成之前，没有任何任务可以运行。
> 一般来说，在执行计算密集型操作或调用可能在异步上下文中阻塞的函数时应格外谨慎。此类操作应尽可能转换为异步操作，或在专用线程上执行，然后使用支持异步的原语（例如通道）进行通信。一些执行器还提供了指示特定异步代码段可能阻塞的机制，或者在原本可能不会阻塞的循环上下文中主动放弃执行的机制，这些机制可以构成解决方案的一部分。一个好的经验法则是，任何 `Future` 都不应能够运行超过 1 毫秒而不返回 `Poll::Pending`。

### 使用 spawn 将所有捆绑在一起

使用异步执行器时，您可能会遇到一个生成 `Future` 的操作。现在我们可以来探索一下这是什么意思！我们通过示例来说明。首先，考虑清单 8-14 中的简单服务器实现。

```rust
async fn handle_client(socket: TcpStream) -> Result<()> {
 // Interact with the client over the given socket.
}
async fn server(socket: TcpListener) -> Result<()> {
 while let Some(stream) = socket.accept().await? {
 handle_client(stream).await?;
 }
}

// 清单 8-14：顺序处理连接
```

&nbsp;&nbsp;&nbsp;&nbsp;顶层服务器函数本质上是一个大型的 `Future`，它会监听新连接，并在新连接到达时执行某些操作。你将这个 `Future` 交给执行器，并命令“运行它”。由于你不希望程序立即退出，所以你可能会让执行器阻塞在这个 `Future` 上。也就是说，调用执行器运行服务器 `Future` 的调用，在服务器 `Future` 解析完成之前不会返回，而这可能永远不会发生（因为另一个客户端可能会在稍后到达）。

&nbsp;&nbsp;&nbsp;&nbsp;现在，每当有新的客户端连接接入时，示例 8-14 中的代码都会创建一个新的 `Future`（通过调用 `handle_client`）来处理该连接。由于处理本身就是一个 `Future`，因此我们等待它，然后继续处理下一个客户端连接。

&nbsp;&nbsp;&nbsp;&nbsp;这种方法的缺点是每次只能处理一个连接——没有并发性。一旦服务器接受连接，就会调用 `handle_client` 函数，由于我们等待它，所以在 `handle_client` 的返回 `Future` 解析完成（大概是客户端离开的时候）之前，我们不会再次循环。

&nbsp;&nbsp;&nbsp;&nbsp;我们可以改进这一点，保存所有客户端 `Future` 的集合，并在服务器接受新连接的循环中检查所有客户端 `Future`，看看是否有任何 `Futur`e 可以取得进展。示例 8-15 展示了这个例子。

```rust
async fn server(socket: TcpListener) -> Result<()> {
    let mut clients = Vec::new();
    loop {
        poll_client_futures(&mut clients)?;
        if let Some(stream) = socket.try_accept()? {
            clients.push(handle_client(stream));
        }
    }
}

// 示例 8-15：使用手动执行器处理连接
```

&nbsp;&nbsp;&nbsp;&nbsp;这至少可以并发处理多个连接，但相当复杂。效率也不太高，因为代码现在处于忙循环状态，在处理现有连接和接受新连接之间切换。而且它每次都必须检查每个连接，因为它不知道哪些连接可以取得进展（如果有的话）。它也不能在任何时候等待，因为这会阻止其他 `Future` 取得进展。您可以实现自己的唤醒程序，以确保代码只轮询那些可以取得进展的 `Future`，但最终这会导致您开发自己的迷你执行器。

&nbsp;&nbsp;&nbsp;&nbsp;坚持只为服务器设置一个内部包含所有客户端连接 `Future` 的任务的另一个缺点是，服务器最终会变成单线程。只有一个任务，为了轮询它，代码必须持有对该任务 `Future` 的独占引用（poll 需要 `Pin<&mut Self`> 参数），而该引用一次只能被一个线程持有。

&nbsp;&nbsp;&nbsp;&nbsp;解决方案是让每个客户端 `Future` 都拥有自己的任务，并让执行器在所有任务之间进行复用。正如你猜到的，你通过生成 `Future` 来实现这一点。执行器将继续阻塞在服务器 `Future` 上，但如果它无法在该 `Future` 上取得进展，它将使用其执行机制在后台同时处理其他任务。最重要的是，如果执行器是多线程的，并且你的客户端 `Future` 是 Send 的，它可以并行运行它们，因为它可以同时持有并发到各个任务的 `&mut` 值。清单 8-16 给出了一个示例，展示了这种实现方式。

```rust
async fn server(socket: TcpListener) -> Result<()> {
    while let Some(stream) = socket.accept().await? {
        // Spawn a new task with the Future that represents this client.
        // The current task will continue to just poll for more connections
        // and will run concurrently (and possibly in parallel) with handle_client.
        spawn(handle_client(stream));
    }
}

// 示例 8-16：生成 Future 来创建更多可并发轮询的任务
```

当你生成一个 `Future` 并将其变为一个任务时，这有点像生成一个线程。`Future` 会继续在后台运行，并与分配给执行器的其他任务并发执行。然而，与生成的线程不同，生成的任务仍然依赖于执行器的轮询。如果执行器停止运行（无论是因为你丢弃了它，还是因为你的代码不再运行执行器的代码），这些生成的任务将停止执行。在服务器示例中，想象一下如果主服务器 `Future` 由于某种原因解析会发生什么。由于执行器已将控制权交还给你的代码，它无法继续执行任何操作。多线程执行器通常会生成后台线程，即使执行器将控制权交还给用户的代码，这些线程也会继续轮询任务，但并非所有执行器都会这样做，因此在依赖此行为之前，请检查你的执行器！

# 总结

在本章中，我们深入了解了 Rust 中异步结构的幕后机制。我们了解了编译器如何实现生成器和自引用类型，以及为什么这项工作对于支持我们现在所知的 `async/await` 至关重要。我们还探索了 `Future` 的执行方式，以及当只有部分任务可以在任何特定时刻执行时，唤醒器如何允许执行器在任务之间进行多路复用。下一章将探讨 Rust 中或许是最深奥、讨论最多的领域：不安全代码。深吸一口气，然后翻开新的一页。








  
